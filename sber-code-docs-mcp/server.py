import os
import faiss
from mcp.server.fastmcp import FastMCP
from llama_index.core import StorageContext, load_index_from_storage, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.llms import MockLLM
from llama_index.vector_stores.faiss import FaissVectorStore

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Settings.llm = MockLLM()
Settings.embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ (Ğ³Ğ´Ğµ Ğ»ĞµĞ¶Ğ¸Ñ‚ server.py)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

STORAGE_DIR = os.path.join(BASE_DIR, "storage")
FAISS_INDEX_PATH = os.path.join(BASE_DIR, "faiss_index.bin")
DOCS_DIR = os.path.join(BASE_DIR, "docs")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ˜ĞĞ”Ğ•ĞšĞ¡Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if not os.path.exists(STORAGE_DIR):
    raise RuntimeError(
        f"Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: {STORAGE_DIR}\n"
        "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ: python builder.py"
    )

if not os.path.exists(FAISS_INDEX_PATH):
    raise RuntimeError(
        f"FAISS Ğ¸Ğ½Ğ´ĞµĞºÑ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {FAISS_INDEX_PATH}\n"
        "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ: python builder.py"
    )

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ FAISS Ğ¸Ğ½Ğ´ĞµĞºÑ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ° (ĞĞ• ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹!)
faiss_index = faiss.read_index(FAISS_INDEX_PATH)
vector_store = FaissVectorStore(faiss_index=faiss_index)

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ LlamaIndex
storage_context = StorageContext.from_defaults(
    persist_dir=STORAGE_DIR,
    vector_store=vector_store
)
index = load_index_from_storage(storage_context)

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ retriever Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
retriever = index.as_retriever(similarity_top_k=7)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP Ğ¡Ğ•Ğ Ğ’Ğ•Ğ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

mcp = FastMCP("SberDocs")


@mcp.tool()
def search_documentation(query: str, category: str = None, top_k: int = 7) -> str:
    """
    ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ SberSalute Code.

    ĞŸĞµÑ€ĞµĞ´Ğ°Ğ¹Ñ‚Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ¸Ğ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ Ğ¸Ğ»Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.

    ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
    - query: Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
    - category: Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 'js-api', 'nlp', 'project', 'root')
    - top_k: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 7, Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 20)

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²:
    - search_documentation("inference") - Ğ¿Ğ¾Ğ¸ÑĞº Ğ²ĞµĞ·Ğ´Ğµ
    - search_documentation("inference", category="nlp") - Ğ¿Ğ¾Ğ¸ÑĞº Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² NLP
    - search_documentation("ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ", top_k=10) - Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    """
    try:
        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ top_k
        top_k = min(max(1, top_k), 20)

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ retriever Ñ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸, Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
        fetch_k = top_k * 3 if category else top_k
        custom_retriever = index.as_retriever(similarity_top_k=fetch_k)

        nodes = custom_retriever.retrieve(query)

        if not nodes:
            return "ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ."

        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ°
        if category:
            category_lower = category.lower().replace("\\", "/")
            filtered_nodes = []
            for node in nodes:
                node_category = node.metadata.get("category", "").lower().replace("\\", "/")
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿ÑƒÑ‚Ğ¸
                if node_category == category_lower or node_category.startswith(category_lower + "/"):
                    filtered_nodes.append(node)
            nodes = filtered_nodes[:top_k]
        else:
            nodes = nodes[:top_k]

        if not nodes:
            return f"ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '{category}'."

        results = []
        for i, node in enumerate(nodes, 1):
            file_path = node.metadata.get("file_path", "ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»")
            node_category = node.metadata.get("category", "")
            score = f"{node.score:.3f}" if node.score else "N/A"
            text_content = node.node.get_content()

            results.append(
                f"â”€â”€â”€ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ {i} â”€â”€â”€\n"
                f"Ğ¤Ğ°Ğ¹Ğ»: {file_path}\n"
                f"ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {node_category}\n"
                f"Ğ ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ: {score}\n"
                f"Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ:\n{text_content}\n"
            )

        return "\n".join(results)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞµ: {e}"


@mcp.tool()
def read_full_file(file_path: str) -> str:
    """
    ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼.

    Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ°Ğ¿ĞºĞ¸ docs/, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:
    - 'js-api/services/caila/inference.md'
    - 'nlp/api/overview.md'
    - 'root/current-datetime.md' (Ğ´Ğ»Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ĞºĞ¾Ñ€Ğ½Ğµ docs/)

    Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‰ĞµĞ½Ğ° Ğ¾Ñ‚ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ° Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ Ğ¿Ğ°Ğ¿ĞºĞ¸ docs/.
    """
    try:
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ "root/" ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾ (Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² ĞºĞ¾Ñ€Ğ½Ğµ docs/)
        if file_path.startswith("root/"):
            file_path = file_path[5:]  # len("root/") = 5

        base = os.path.abspath(DOCS_DIR)
        abs_path = os.path.abspath(os.path.join(base, file_path))

        # Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ path traversal
        if not abs_path.startswith(base):
            return "ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ Ğ¿Ğ°Ğ¿ĞºĞ¸ docs/ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½."

        if not os.path.exists(abs_path):
            return f"ĞÑˆĞ¸Ğ±ĞºĞ°: Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {file_path}"

        with open(abs_path, "r", encoding="utf-8") as f:
            content = f.read()

        return f"â”€â”€â”€ Ğ¤Ğ°Ğ¹Ğ»: {file_path} â”€â”€â”€\n\n{content}"

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°: {e}"


@mcp.tool()
def list_categories() -> str:
    """
    ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹ (Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¾Ğ²) Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.

    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿Ğ¾Ğº Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ docs/ Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹.
    ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.
    """
    try:
        categories = {}

        for root, dirs, files in os.walk(DOCS_DIR):
            md_files = [f for f in files if f.endswith(".md")]
            if md_files:
                rel_path = os.path.relpath(root, DOCS_DIR)
                if rel_path == ".":
                    rel_path = "root"
                categories[rel_path] = {
                    "count": len(md_files),
                    "files": md_files[:5]  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 5 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°
                }

        if not categories:
            return "ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² Ğ¿Ğ°Ğ¿ĞºĞµ docs/"

        result = ["â”€â”€â”€ ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ â”€â”€â”€\n"]

        for cat, info in sorted(categories.items()):
            result.append(f"ğŸ“ {cat} ({info['count']} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²)")
            for f in info["files"]:
                result.append(f"   â””â”€ {f}")
            if info["count"] > 5:
                result.append(f"   â””â”€ ... Ğ¸ ĞµÑ‰Ñ‘ {info['count'] - 5} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹: {e}"


@mcp.tool()
def find_file_by_name(filename: str) -> str:
    """
    ĞŸĞ¾Ğ¸ÑĞº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸.

    Ğ˜Ñ‰ĞµÑ‚ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½ÑƒÑ Ğ¿Ğ¾Ğ´ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ² Ğ¸Ğ¼ĞµĞ½Ğ¸.
    ĞŸĞ¾Ğ¸ÑĞº Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¾Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ñ‹Ğ¹.

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
    - find_file_by_name("inference") - Ğ½Ğ°Ğ¹Ğ´Ñ‘Ñ‚ inference.md, simple-inference.md
    - find_file_by_name("overview") - Ğ½Ğ°Ğ¹Ğ´Ñ‘Ñ‚ Ğ²ÑĞµ overview.md Ñ„Ğ°Ğ¹Ğ»Ñ‹
    """
    try:
        filename_lower = filename.lower()
        found_files = []

        for root, dirs, files in os.walk(DOCS_DIR):
            for f in files:
                if f.endswith(".md") and filename_lower in f.lower():
                    rel_path = os.path.relpath(root, DOCS_DIR)
                    if rel_path == ".":
                        category = "root"
                        full_path = f
                    else:
                        category = rel_path.replace(os.sep, "/")
                        full_path = f"{category}/{f}"

                    found_files.append({
                        "file": f,
                        "path": full_path,
                        "category": category
                    })

        if not found_files:
            return f"Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ñ '{filename}' Ğ² Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹."

        result = [f"â”€â”€â”€ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {len(found_files)} â”€â”€â”€\n"]

        for item in sorted(found_files, key=lambda x: x["path"]):
            result.append(f"ğŸ“„ {item['file']}")
            result.append(f"   ĞŸÑƒÑ‚ÑŒ: {item['path']}")
            result.append(f"   ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {item['category']}")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞµ Ñ„Ğ°Ğ¹Ğ»Ğ°: {e}"


@mcp.tool()
def list_files_in_category(category: str) -> str:
    """
    ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¹ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸.

    ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
    - category: Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 'js-api', 'nlp/api', 'root')

    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸ ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼Ğ¸ (Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸) ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°.
    """
    try:
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ
        if category == "root":
            target_dir = DOCS_DIR
        else:
            category = category.replace("/", os.sep)
            target_dir = os.path.join(DOCS_DIR, category)

        if not os.path.exists(target_dir):
            return f"ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ '{category}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°."

        if not os.path.isdir(target_dir):
            return f"'{category}' Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ĞµĞ¹ (Ğ¿Ğ°Ğ¿ĞºĞ¾Ğ¹)."

        files_info = []

        for f in sorted(os.listdir(target_dir)):
            if f.endswith(".md"):
                file_path = os.path.join(target_dir, f)
                # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ½ĞµĞ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ (Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº)
                title = ""
                try:
                    with open(file_path, "r", encoding="utf-8") as file:
                        for line in file:
                            line = line.strip()
                            if line and line.startswith("#"):
                                title = line.lstrip("#").strip()
                                break
                            elif line and not line.startswith("["):
                                title = line[:80]
                                break
                except:
                    title = "(Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ)"

                files_info.append({
                    "file": f,
                    "title": title or "(Ğ±ĞµĞ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°)"
                })

        if not files_info:
            return f"Ğ’ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '{category}' Ğ½ĞµÑ‚ .md Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²."

        result = [f"â”€â”€â”€ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ² ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '{category}' ({len(files_info)}) â”€â”€â”€\n"]

        for item in files_info:
            result.append(f"ğŸ“„ {item['file']}")
            result.append(f"   {item['title']}")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ¿Ğ¸ÑĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {e}"


@mcp.tool()
def get_table_of_contents(file_path: str) -> str:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ğ³Ğ»Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸) Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.

    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²ÑĞµ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ (#, ##, ###) Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñƒ.

    ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
    - file_path: Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ docs/ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: 'nlp/api/inference.md')
                 Ğ´Ğ»Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ĞºĞ¾Ñ€Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ 'root/filename.md'
    """
    try:
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ "root/" ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾
        if file_path.startswith("root/"):
            file_path = file_path[5:]

        base = os.path.abspath(DOCS_DIR)
        abs_path = os.path.abspath(os.path.join(base, file_path))

        # Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ path traversal
        if not abs_path.startswith(base):
            return "ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ Ğ¿Ğ°Ğ¿ĞºĞ¸ docs/ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½."

        if not os.path.exists(abs_path):
            return f"ĞÑˆĞ¸Ğ±ĞºĞ°: Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {file_path}"

        headings = []
        with open(abs_path, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.rstrip()
                if line.startswith("#"):
                    # ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°
                    level = 0
                    for char in line:
                        if char == "#":
                            level += 1
                        else:
                            break
                    title = line[level:].strip()
                    if title:
                        indent = "  " * (level - 1)
                        headings.append(f"{indent}â€¢ {title} (ÑÑ‚Ñ€Ğ¾ĞºĞ° {line_num})")

        if not headings:
            return f"Ğ’ Ñ„Ğ°Ğ¹Ğ»Ğµ '{file_path}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²."

        result = [f"â”€â”€â”€ ĞĞ³Ğ»Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ: {file_path} â”€â”€â”€\n"]
        result.extend(headings)

        return "\n".join(result)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ğ¾Ğ³Ğ»Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ: {e}"


@mcp.tool()
def search_exact(text: str, category: str = None) -> str:
    """
    Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº (grep-Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ñ‹Ğ¹).

    Ğ˜Ñ‰ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ²Ğ¾ Ğ²ÑĞµÑ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸.
    ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ², URL, Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² ĞºĞ¾Ğ´Ğ°.

    ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
    - text: Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° (Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¾Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ñ‹Ğ¹)
    - category: Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾, Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¹ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
    - search_exact("$jsapi") - Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ $jsapi
    - search_exact("smartapp-code.sberdevices.ru") - Ğ½Ğ°Ğ¹Ñ‚Ğ¸ URL
    """
    try:
        text_lower = text.lower()
        results = []
        max_results = 20

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
        if category:
            if category == "root":
                search_dirs = [DOCS_DIR]
            else:
                search_dirs = [os.path.join(DOCS_DIR, category.replace("/", os.sep))]
        else:
            search_dirs = [DOCS_DIR]

        for search_dir in search_dirs:
            if not os.path.exists(search_dir):
                continue

            for root, dirs, files in os.walk(search_dir):
                if len(results) >= max_results:
                    break

                for f in files:
                    if len(results) >= max_results:
                        break

                    if not f.endswith(".md"):
                        continue

                    file_path = os.path.join(root, f)
                    rel_path = os.path.relpath(file_path, DOCS_DIR).replace(os.sep, "/")

                    try:
                        with open(file_path, "r", encoding="utf-8") as file:
                            for line_num, line in enumerate(file, 1):
                                if text_lower in line.lower():
                                    # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
                                    line_preview = line.strip()
                                    if len(line_preview) > 100:
                                        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
                                        pos = line.lower().find(text_lower)
                                        start = max(0, pos - 30)
                                        end = min(len(line_preview), pos + len(text) + 30)
                                        line_preview = "..." + line_preview[start:end] + "..."

                                    results.append({
                                        "file": rel_path,
                                        "line": line_num,
                                        "content": line_preview
                                    })

                                    if len(results) >= max_results:
                                        break
                    except:
                        continue

        if not results:
            msg = f"Ğ¢ĞµĞºÑÑ‚ '{text}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
            if category:
                msg += f" Ğ² ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ '{category}'"
            return msg + "."

        output = [f"â”€â”€â”€ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹: {len(results)} â”€â”€â”€\n"]

        for r in results:
            output.append(f"ğŸ“ {r['file']}:{r['line']}")
            output.append(f"   {r['content']}")
            output.append("")

        if len(results) >= max_results:
            output.append(f"(Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ñ‹ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ {max_results} Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²)")

        return "\n".join(output)

    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞµ: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # MCP-ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ: ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ print() â€” ÑÑ‚Ğ¾ Ğ»Ğ¾Ğ¼Ğ°ĞµÑ‚ JSON-RPC
    # Ğ’ÑĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¸Ğ´Ñ‚Ğ¸ Ğ² stderr Ğ¸Ğ»Ğ¸ Ğ² Ñ„Ğ°Ğ¹Ğ»
    mcp.run()
